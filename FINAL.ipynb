{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "songs = pd.read_csv('data/songs.csv')\n",
    "song_labels = pd.read_csv('data/song_labels.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "save_for_later = pd.read_csv('data/save_for_later.csv')\n",
    "dummy_submission = pd.read_csv('data/dummy_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_init, train_rem = train_test_split(train, train_size = 0.3, random_state = 1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id_list = train['customer_id'].unique()\n",
    "song_id_list = train['song_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Matrix Factorization\n",
    "learning_rate = 1e-2\n",
    "iters = 90\n",
    "dim = 100\n",
    "reg = 0.05\n",
    "# Initialization\n",
    "\n",
    "customer_weights = {}\n",
    "for customer in customer_id_list:\n",
    "    np.random.seed(0)\n",
    "    customer_weights[customer] = np.random.uniform(0, 10e-10, dim)\n",
    "    \n",
    "song_weights = {}\n",
    "for song in song_id_list:\n",
    "    np.random.seed(0)\n",
    "    song_weights[song] = np.random.uniform(0, 10e-10, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Matrix Factorization\n",
    "for i in range(iters):\n",
    "    for k in range(len(train_init.index.to_numpy())):\n",
    "        customer_weight = customer_weights[train_init['customer_id'].iloc[k]]\n",
    "        song_weight = song_weights[train_init['song_id'].iloc[k]]\n",
    "        y = train_init['score'].iloc[k]\n",
    "        \n",
    "        temp = y - np.dot(customer_weight, song_weight)\n",
    "        customer_weight_new = customer_weight + learning_rate*(temp*song_weight-reg*customer_weight)\n",
    "        song_weight_new = song_weight + learning_rate*(temp*customer_weight-reg*song_weight)\n",
    "        customer_weights[train_init['customer_id'].iloc[k]] = customer_weight_new\n",
    "        song_weights[train_init['song_id'].iloc[k]] = song_weight_new\n",
    "    estimates_train_rem = []\n",
    "    for k in range(len(train_rem.index.to_numpy())):\n",
    "        customer_weight = customer_weights[train_rem['customer_id'].iloc[k]]\n",
    "        song_weight = song_weights[train_rem['song_id'].iloc[k]]\n",
    "        estimate = np.dot(customer_weight, song_weight)\n",
    "        estimates_train_rem.append(estimate)\n",
    "    estimates_train_init = []\n",
    "    for k in range(len(train_init.index.to_numpy())):\n",
    "        customer_weight = customer_weights[train_init['customer_id'].iloc[k]]\n",
    "        song_weight = song_weights[train_init['song_id'].iloc[k]]\n",
    "        estimate = np.dot(customer_weight, song_weight)\n",
    "        estimates_train_init.append(estimate)\n",
    "    y_train_rem = train_rem['score'].to_numpy()\n",
    "    y_train_init = train_init['score'].to_numpy()\n",
    "    estimates_train_rem = np.array(estimates_train_rem)\n",
    "    estimates_train_init = np.array(estimates_train_init)\n",
    "    train_error_rem = (1/len(y_train_rem))*np.linalg.norm(y_train_rem - estimates_train_rem)**2\n",
    "    train_error_init = (1/len(y_train_init))*np.linalg.norm(y_train_init - estimates_train_init)**2\n",
    "    print(f'iter {i} rem {train_error_rem} init {train_error_init}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_weights_df = pd.DataFrame(customer_weights)\n",
    "customer_weights_df = customer_weights_df.transpose()\n",
    "customer_weights_df['customer_id'] = customer_weights_df.index\n",
    "train_rem = train_rem.merge(customer_weights_df, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_weights_df = pd.DataFrame(song_weights)\n",
    "song_weights_df = song_weights_df.transpose()\n",
    "song_weights_df['song_id'] = song_weights_df.index\n",
    "songs = songs.merge(song_weights_df, on = 'song_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_train = []\n",
    "for k in range(len(train_rem.index.to_numpy())):\n",
    "    customer_weight = customer_weights[train_rem['customer_id'].iloc[k]]\n",
    "    song_weight = song_weights[train_rem['song_id'].iloc[k]]\n",
    "    estimate = np.dot(customer_weight, song_weight)\n",
    "    estimates_train.append(estimate)\n",
    "    \n",
    "train_rem['estimates'] = estimates_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_labels_pivot = song_labels.pivot_table(index = 'platform_id', columns = 'label_id', values = 'count')\n",
    "song_labels_pivot = song_labels_pivot.fillna(0)\n",
    "song_labels_pivot = song_labels_pivot.applymap(lambda x: np.log(1+np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=100, max_iter = 1000, verbose = 1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_labels_transformed = nmf.fit_transform(song_labels_pivot)\n",
    "song_labels_transformed_df = pd.DataFrame(song_labels_transformed, index = song_labels_pivot.index)\n",
    "songs = pd.merge(songs, song_labels_transformed_df, on = 'platform_id', how = 'left')\n",
    "songs = songs.drop(['platform_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_song_mean = train.groupby('song_id').mean()\n",
    "song_scores = train.merge(train_song_mean, on = 'song_id', how = 'left')\n",
    "song_scores = song_scores[['song_id', 'score_y']]\n",
    "song_scores.drop_duplicates('song_id', keep = 'first', inplace = True)\n",
    "songs = songs.merge(song_scores, on = 'song_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_num_ratings = train['song_id'].value_counts().to_frame()\n",
    "song_num_ratings['num_ratings'] = song_num_ratings['song_id']\n",
    "song_num_ratings['song_id'] = song_num_ratings.index\n",
    "songs = songs.merge(song_num_ratings, on = 'song_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.drop_duplicates('song_id', keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.merge(train_rem, save_for_later, on=['customer_id','song_id'], how='left', indicator='Exist')\n",
    "train_rem = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(train_rem, songs, on = ['song_id'], how = 'left')\n",
    "Y_train = X_train['score']\n",
    "X_train.drop(['score'], axis = 1, inplace = True)\n",
    "X_train['released_year'] = X_train['released_year'].fillna(-999)\n",
    "X_train['language'] = X_train['language'].fillna('none')\n",
    "X_train['number_of_comments'] = X_train['number_of_comments'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(depth = 8, num_trees = 6000, random_seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, cat_features = [0,1, 103, 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(customer_weights_df, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_test = []\n",
    "for k in range(len(test.index.to_numpy())):\n",
    "    customer_weight = customer_weights[test['customer_id'].iloc[k]]\n",
    "    song_weight = song_weights[test['song_id'].iloc[k]]\n",
    "    estimate = np.dot(customer_weight, song_weight)\n",
    "    estimates_test.append(estimate)\n",
    "    \n",
    "test['estimates'] = estimates_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test, save_for_later, on=['customer_id','song_id'], how='left', indicator='Exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.merge(test, songs, on = ['song_id'], how = 'left')\n",
    "X_test['released_year'] = X_test['released_year'].fillna(-999)\n",
    "X_test['language'] = X_test['language'].fillna('none')\n",
    "X_test['number_of_comments'] = X_test['number_of_comments'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_final = pd.DataFrame(y_test_pred)\n",
    "y_final['score'] = y_final[0]\n",
    "y_final.drop(0, axis = 1, inplace = True)\n",
    "y_final['test_row_id'] = y_final.index\n",
    "y_final = y_final[['test_row_id', 'score']]\n",
    "y_final.to_csv('predicted.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
